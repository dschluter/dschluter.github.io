<h1>Meta-analysis</h1>
In this workshop we explore the "analysis of analyses". The first exercise will require you to make the step-by-step calculations for fixed and random effects models. The goal is to give a sense of why the two models yield different results. It would be truly wonderful if <code>lm</code> and <code>lme</code> could take care of all the gritty calculations in a familiar setting, but it is not easy to get the correct variances using these programs. So we'll start by going step by step. See the "Meta" tab at the R tips pages for help.
<h2><a name="bibs"></a><span style="font-weight: bold;">Aggressive bibs</span></h2>
The black throat patch or bib of male house sparrows, <i>Passer domesticus</i>, is called a "badge" because bib size seems to be correlated with male social status. Sanchez-Tojar et al. (2018) compiled results of published and unpublished studies that investigated the relationship between male badge size and measurements of male size, behavior and reproductive success (<i>Meta-analysis challenges a textbook example of status signalling and demonstrates publication bias</i>. eLife 2018;7:e37385). The data are <a href="../../../data/sparrow.csv">here</a>.

The correlation coefficient <i>r</i> was the effect size measuring association between bib size and these other traits. 87 estimates of the correlation between bib size and male fighting ability ("status") are included. The study included both published and unpublished data obtained from researchers. These data are from the Supplement file "Meta4.csv" of Sanchez-Tojar et al. (2018). Most of the correlations were obtained from behavioral observations made of birds in aviaries.
<ol>
 	<li>View the data and examine it closely. The data set is not large, but it has aspects in common with larger compilations used in meta-analyses, and raises many of the same questions. First, there are many more entries than published studies. Repeated entries from the same study represent different nearby populations, or measurements taken in different years or on different interacting groups of individuals from the same population. Can the 87 effect sizes in the table therefore be considered independent? Should we average all the values from the same population, or from the same study, before continuing? Note that many of the data sets have a very small sample size <i>N</i> (e.g., the number of individual birds in a single group). Should these be included or excluded? Welcome to meta-analysis.

For the purposes of this exercise, let's treat the 87 effect sizes as though they are independent and belong to a single fixed class. I hope this does not shock you.</li>
 	<li>Create a simple scatter or "funnel" plot depicting the relationship between effect size and sample size for the published house sparrow data (indicated by the variable <i>published</i>). Include a dashed line in the plot for <i>r</i> = 0. What pattern would you expect to see if there was publication bias? Is such a pattern evident in your plot?</li>
 	<li>Statistical analysis of correlations begins by converting <i>r</i> to the Fisher's <i>z</i>-scale. The reason is that on the <i>z</i>-scale, the sampling distribution for the correlation is approximately normal and the standard error is independent of <i>z</i>. The transformed variable is indicated by the variable <i>Zr</i>. The transformation is
<i>z</i> = 0.5 ln((1 + <i>r</i>)/(1 - <i>r</i>)), or equivalently, <i>z</i> = tanh<sup>-1</sup>(<i>r</i>)</li>
 	<li>A convenient feature of the Fisher <i>z</i> is that the approximate standard error of an estimate depends only on the sample size <i>N</i> (i.e., number of birds) used in each study. The squared standard error is indicated by the variable <i>VZr</i>. The formula is
SE<sub>z</sub> = 1/√<span style="text-decoration:overline">(<i>n</i> - 3)</span>.</li>
</ol>
<h3>Fixed effects meta-analysis</h3>
Under the <b>fixed effects</b> model, we assume that all studies in the meta-analysis share the same true effect size. The variation among the studies are assumed to result only from sampling error (i.e., chance). For the purposes of this exercise, let's begin by fitting the fixed effects model to the sparrow data. Perhaps the fixed effects model is reasonable: the different studies were all carried out on the same species (house sparrow), and they correlated the same variables measured in similar (though not identical) ways. Fitting the fixed effects model involves calculating a weighted average of the separate correlations to yield an estimate the one true effect size. Refer to the "Meta" tab at the R tips web site for help with formulas and concepts.
<ol>
 	<li>To estimate the mean effect size, we will weight each correlation according to the magnitude of its sampling variance, which takes into account the different sample sizes of the studies. Each weight is the inverse of the squared standard error. Calculate the weights for the sparrow data. Notice how the weights vary with sample size.</li>
 	<li>Fit the model by calculating the weighted mean, <span style="text-decoration:overline"><i>z</i></span>, of the <i>z</i>-transformed correlations. R will calculate a weighted mean if you ask it. The result is your estimate of the true mean effect size. In what way does it differ from the unweighted mean of the <i>z</i>-transformed correlations?</li>
 	<li>Calculate the standard error of the weighted mean. This standard error measures uncertainty of the estimate of true effect size.</li>
 	<li>Calculate an approximate 95% confidence interval for the mean of the transformed effect sizes using the normal approximation.</li>
 	<li>Convert your estimated mean effect size from (2) back to the untransformed correlation, to obtain the mean effect size <span style="text-decoration:overline"><i>r</i></span>. This requires back-transforming,*
<span style="text-decoration:overline"><i>r</i></span> = tanh(<span style="text-decoration:overline"><i>z</i></span>) or, equivalently, <span style="text-decoration:overline"><i>r</i></span> = (e<sup>2<span style="text-decoration:overline"><i>z</i></span></sup> - 1)/(e<sup>2<span style="text-decoration:overline"><i>z</i></span></sup> + 1).
Add a horizontal line indicating the mean effect size to your funnel plot created in the previous section.</li>
 	<li>Apply the same back-transformation to the lower and upper limits of your confidence interval in (4) to yield the 95% confidence interval for the mean correlation coefficient.**</li>
</ol>
<small>*  0.162
** (0.086 0.236)</small>
<h3>Random effects meta-analysis</h3>
Under the <b>random effects</b> model we assume that each study estimates a system-specific effect size. There is no "one true" effect size under this model, only a mean effect size. This is more realistic than the fixed effects model for most data in ecology and evolution. Even though each study of male bibs was carried out on the same species (house sparrow), there is nevertheless likely to be heterogeneity from population to population, year to year, and even researcher to researcher if study methods are not the same.
<ol>
 	<li>To fit the random effects model we need to estimate the variance among the system-specific effect sizes, Τ<sup>2</sup> ("tau squared"). One way to estimate it involves calculating the heterogeneity among the observed effect sizes (<i>Q</i>), and then "correcting" by subtracting the within-study sampling variance. The correction is needed because the variance among the observed effect sizes among studies is inflated by within-study sampling error. To begin, calculate <i>Q</i>, the weighted heterogeneity among the observed <i>Zr</i> values.</li>
 	<li>Then estimate Τ<sup>2</sup> by subtraction, being careful not to allow a negative value (since Τ<sup>2</sup> is a variance, which can't be negative).*</li>
 	<li>Using Τ<sup>2</sup>, calculate new weights for the effect sizes of each study under the random effects model. Examine these new weights <i>w'</i> and compare them to the weights <i>w</i> under the fixed effects model. How are they different? Is as much weight given to large-sample studies, relative to small-sample studies, in the random effects model as in the fixed effects model?</li>
 	<li>Calculate the weighted mean effect size <span style="text-decoration:overline"><i>z</i></span> under the random effects model. The procedure is the same as that used before for the fixed effects model except that here we will use the new weights <i>w'</i> calculated in the previous step. Back-transform to get the estimated mean correlation <span style="text-decoration:overline"><i>r</i></span>.** Add the estimated mean correlation to your funnel plot. Compare your result to the effect size estimated under the fixed effects model. Is it the same?</li>
 	<li>Calculate the standard error (SE) of the mean <span style="text-decoration:overline"><i>z</i></span>. The formula is the same as that in the fixed-effects model except that here we will use the new weights.</li>
 	<li>Calculate the 95% confidence interval for the mean effect size under the random effects model. Is the confidence interval narrower, about the same, or wider than that calculated under the fixed effects model? Why?</li>
 	<li>Finally, back-transform to get the lower and upper limits of the 95% confidence interval for the mean correlation <span style="text-decoration:overline"><i>r</i></span>. ***</li>
 	<li>Optional: make a function. Now that you've done the hard work of programming R to calculate effect sizes for random and fixed effects models, why don't you try to make a function that would carry it out on any set of data? There are a few notes on how to write a function on the "Vector" tab of the R tips page.</li>
</ol>
<small>*   0.1342
**  0.1513
*** (0.0224 0.2752)</small>
<h3>Publication bias?</h3>
Use the <code>metafor</code> package to examine and compare correlations from published and unpublished studies. See the "Meta" tab at the R tips web site for help.
<ol>
 	<li>To begin, use the package to recalculate the quantities you obtained "by hand" in the above exercise on random effects meta-analysis. Did you get the same results? So much easier!</li>
 	<li>Produce a funnel plot of the data.</li>
 	<li>Produce a forest plot of the data.</li>
 	<li>Fit a meta-analysis model that includes the moderator variable "publication". Use the summary command to estimate the difference between the means for published and unpublished studies. (Note that these values are computed on the z-transformed scale.) Do published and unpublished studies yield different results?</li>
</ol>
<h2><a name="latitude"></a>The latitudinal gradient in species diversity</h2>
There are more species in the tropics than in the temperate zone, but how strong and how general is this pattern? The latitudinal gradient is steeper for some taxa than for others, and may even be reversed in some groups. It may also vary longitudinally and between the northern and southern hemispheres. There is no consensus on the causes of the latitudinal gradient in species diversity.

Hillebrand (2004; On the generality of the latitudinal diversity gradient. American Naturalist 163:192-211) combed the literature for studies that measured the relationship between diversity and latitude. His database is <a href="../../../data/hillebrand.csv">HERE</a>. Download and read into R. The data file was obtained from <a href="http://www.jstor.org.ezproxy.library.ubc.ca/action/showPopup?citid=citart1&amp;id=tb5&amp;doi=10.1086%2F381004">Table A1</a> (UBC link) in Hillebrand (2004).

Inspect the variables in the Hillebrand data set. They include measures of the latitudinal gradient and some grouping variables that will allow us to compare the gradient between situations. His <a href="http://www.jstor.org.ezproxy.library.ubc.ca/action/showPopup?citid=citart1&amp;id=tb6&amp;doi=10.1086%2F381004">Table B2</a> (UBC link) explains the various grouping variables. For this exercise, we'll focus on the estimate from each study of the steepness of the relationship between species diversity and latitude, described by the variables:
<b>Slope.b</b>: The regression slope of the relationship between species diversity and absolute latitude, per degree latitude. A negative slope implies that diversity declines with increasing latitude (from the equator to the poles), whereas a positive slope represents a reversed gradient.
<b>SE.b</b>: The associated standard error of slope.
<b>Measure</b>: The measure of species diversity used in the calculation of regression slope. The most frequent is <i>S</i>, simply species richness (number of species), but studies using other metrics were also included. See <a href="http://www.jstor.org.ezproxy.library.ubc.ca/action/showPopup?citid=citart1&amp;id=tb6&amp;doi=10.1086%2F381004">Table B2</a> in the original article for details.
<b>N</b>: The number of sample points used to calculate the slope.

Use the <code>metafor</code> package to examine and compare latitudinal gradients. See the "Meta" tab at the R tips web site for help.
<ol>
 	<li>Retain only those studies having a non-missing value for the slope variable, and for which the measure of species diversity is species richness. How many estimates of slope (latitudinal gradients) are included in this data set*? From how many unique studies are these estimates obtained (as indicated by the variable "Source")*? How many unique types of organisms are included, according to the variable "Organisms"*? What do these numbers indicate about the likelihood that the many estimates of slope included in the meta-analysis represent an independent sample of estimates from nature?</li>
 	<li>Produce a funnel plot of the relationship between the effect size (slope) and its standard error. You'll notice that there are some crazy outliers, and I have confirmed from the source that at least one is a mistake. For the purposes of this exercise, retain only those studies having an absolute value of slope less than 40. An estimated rate of change in species diversity of more than 40 species per degree latitude seems a bit unrealistic.</li>
 	<li>Is the mean slope of the latitudinal gradient positive or negative? Use the <code>meta</code> package to find out**. Should you use the fixed effects or the random effects model? Why? Does your answer agree with the conventional picture of the latitudinal gradient? Note that the confidence interval assumes a normal distribution of effect sizes, so you should take these upper and lower limits with the appropriate degree of skepticism.</li>
 	<li>Would you expect homeotherms or ectotherms to have a steeper average latitudinal gradient? Analyze the Hillebrand data set to find out. Did the answer agree with your expectation?</li>
 	<li>Is the mean latitudinal gradient in species diversity steepest in marine, terrestrial, or freshwater taxa?</li>
 	<li>Is the mean latitudinal gradient in species diversity steeper in the northern or southern hemisphere?</li>
 	<li>Is the mean gradient steeper in the Old World or the New World? Use the categories of the variable "Longitude" to find out.</li>
 	<li>Which trophic groups show a particularly weak mean latitudinal gradient?</li>
</ol>
<small>* 385; 175; 134. The 385 estimates are unlikely to represent a random sample of estimates from nature.
** -1.0568. On average, species richness drops about 1.06 species per degree latitude. You should use the random effects model, because each taxon is expected to have a different "true" mean latitudinal gradient.
</small>

<code><!--
<h2><a name="selection"></a>Natural selection</h2>
How strong is natural selection, typically? Kingsolver et al. surveyed studies published between 1984 and 1997 and tallied up a total of 1364 measurements of directional selection on quantitative phenotypic traits (2001, <i>The strength of phenotypic selection in natural populations</i>. Am. Nat. 157: 245-261). Their database on directional selection is <a href="../../../data/selection.csv">here</a>. (Their additional summaries of non-linear selection are not included). Download and read into R. 

Effect sizes were selection coefficients, estimated on traits standardized to have mean 0 and variance 1 before selection. The measures of selection are <i>s</i> and <i>beta</i> (&beta;). <i>s</i> is the directional selection differential, which for survival data is the population mean of the survivors minus the mean before selection (in units of standard deviations). <i>beta</i> is a partial regression coefficient from a multiple regression of relative fitness on a suite of traits. It attempts to estimate selection directly on a trait, while removing those changes to a trait caused by its correlation with other traits under selection. Most other variables are self-explanatory. The following is not a full list:
<ul>
 	<li>fit.comp = fitness component (F = Fecundity/Fertility, M = mating success, S= survival, T = total fitness, N = Net reproductive rate, O = parasite burden)</li>
 	<li>traitclass = trait type (MO = Morphology, LH = life history or phenology, BE = behavior, PC = principal component, I = interaction)</li>
 	<li>studytype = study type (C = cross-sectional, L = longitudinal)</li>
 	<li>N = sample size</li>
</ul>
<ol>
 	<li>Examine the first few lines of the data to get a feel for how the data is made up of measurements from many traits and studies. Notice that the same study might be listed multiple times, for example once for each trait measured.</li>
 	<li>Draw a funnel plot of the selection differential, <i>s</i>. Notice the a huge range of sample sizes. Since the precision of an estimate (standard error, confidence interval) in general scales not with <i>N</i> but with the square root of <i>N</i>, try plotting <i>s</i> against the square root of <i>N</i> or the log of <i>N</i> to better see the patterns. You can also plot <i>s</i> against the inverse of the standard error of <i>s</i> ("se.s"), but you will notice that standard errors are missing for many estimates.</li>
 	<li>Calculate the mean selection differential. For now, use the ordinary, unweighted mean. Consider that this represents the average shift in the mean of traits before and after selection, in units of standard deviations, averaged over many measurements and studies. Examine the result. If nature was in balance, we might expect the mean to be close to zero (just as much selection upward on traits as downward, overall). How should we interpret the fact that the mean <i>s</i> is not close to zero? (This is a biological question, not a statistics question!)</li>
 	<li>Let's look at this data in a slightly different way. Draw a funnel plot of the <b>absolute value</b> of the selection coefficient <i>s</i>. What is the mean of the absolute values? This is even larger than before because we are averaging each shift regardless of direction.</li>
 	<li>Plot the regression line to describe how the absolute value of the selection coefficient changes with sample size (use the measure of sample size from your funnel plot). Notice the pattern of declining selection with increasing sample size. Can publication bias explain this result?(Nobody has come up with a really satisfactory explanation for this pattern.)</li>
 	<li>Is the absolute value of selection on traits likely to be stronger in association with <b>reproduction</b> or with <b>survival</b>? Why? To test your answer, calculate the median selection differential for different fitness components (median is probably more reliable than mean because the values are skewed). Also calculate the sample sizes in each category for reference. Repeat the calculation for the selection gradient -- are they the same as for the selection differentials?</li>
 	<li>If time permits, explore other patterns in the data. Is selection just as strong in plants as in animals? Does selection strength differ depending on whether the study was cross-sectional or longitudinal? Does selection differ among types of traits?  Examine also the sample sizes in each group (plants vs animals, type of study, type of trait). Are some groups overrepresented in the data compared to others?</li>
</ol>
Postscript: We haven't had a chance to carry out any serious quantitative meta-analyses on these data, as we did with the sparrow data above, because the shortage of standard errors here means that we wouldn't get very far. If we were going to go this route we would at some point want to take stock of the multiple measurements from each study. It might be prudent to include analyses of summary measures made on data from individual studies to reduce the amount of non-independence in the data.
--> </code>