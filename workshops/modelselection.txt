<h1>Model selection</h1>
Selecting among candidate models requires a <b>criterion</b> for evaluating and comparing models, and a <b>strategy</b> for searching the possibilities. In this workshop we will explore some of the tools available in R for model selection. If you are working from your own computer you may need to download and install the <code>leaps</code> package from the CRAN website to carry out all the exercises.

For help with these exercises, see the "Fit model" link on the Rtips web page.
<h2><a name="bmr"></a>Scaling of basal metabolic rate in mammals</h2>
Savage et al. (2004, Functional Ecology 18: 257-282) used data to reevaluate competing claims for the value of the allometric scaling parameter β relating whole-organism metabolic rate to body mass in endotherms:
&nbsp;&nbsp;&nbsp;&nbsp;<i>BMR = αM</i><sup>β</sup>
In this formula <i>BMR</i> is basal metabolic rate, <i>M</i> is body mass, and α is a constant. On a log scale this can be written as
&nbsp;&nbsp;&nbsp;&nbsp;<i></i>log(<i>BMR</i>) = log(α) + β log(<i>M</i>),
where β is now a slope parameter of an ordinary linear regression -- a linear model. Theory based on optimization of hydrodynamic flows through the circulation system predicts that the exponent should be β = 3/4, whereas we would expect β = 2/3 if metabolic rate scales with heat dissipation and therefore body surface area. These alternative scaling relationships represent distinct biophysical hypotheses. We will use them as candidate models and apply model selection procedures to compare their fits to data.

Savage et al. compiled data from 626 species of mammals. To simplify, and reduce possible effects of non-independence of species data points, they took the average of log(<i>BMR</i>) among species in small intervals of log(<i>M</i>). The resulting values of basal metabolic rate and mass can be downloaded <a href="../../../data/bmr.csv">HERE</a>. Body mass is in grams, whereas basal metabolic rate is in watts.
<ol>
 	<li>Plot the data. Is the relationship between mass and metabolic rate linear on a log scale?</li>
 	<li>Fit a linear model to the log-transformed data (original data are not on the log scale). What is the estimate of slope?</li>
 	<li>Produce a 95% confidence interval for the estimate of slope. Does the interval include either of the candidate values for the scaling parameter β?</li>
 	<li>Add the best-fit regression line to the plot in (1).</li>
 	<li>Now compare the fits of the two candidate models to the data. To accomplish this you need to force a regression line having a specified slope through the (log-transformed) data. See the end of the part on simple linear regression in the "Fit a linear model" section of the "Fit model" tab at the R tips page.</li>
 	<li>Replot the data indicating the relationship between log(<i>M</i>) and log(<i>BMR</i>). Add to this plot the best-fit line having slope 3/4. Repeat this for the slope 2/3. By eye, which line appears to fit the data best?</li>
 	<li>Compare the residual sum of squares of the two models you fit in (5). Which has the smaller value? Do these values agree with your visual assessment of your plots in (6)?</li>
 	<li>Calculate the log-likelihood of each model fitted in (5). Which has the higher value?</li>
 	<li>Calculate AIC for the two models, and the AIC difference*. By this criterion, which model is best? How big is the AIC difference?</li>
 	<li>In general terms, what does AIC score attempt to measure?</li>
 	<li>Calculate the Akaike weights of the two models**. Which has the higher weight of evidence in its favor? These weights would be used in Multimodel Inference (such as model averaging), which we won't go into in this course. The weights should sum to 1. (They are sometimes interpreted as the posterior probability that the given model is the "best" model, assuming that the "best" model is one of the set of models being compared, but this interpretation makes assumptions that we won't go into right now.)</li>
 	<li>Summarize the overall findings. Do both models have some support, according to standard criteria, or does one of the two models have essentially no support?</li>
 	<li>Why is it not possible to compare the two models using a conventional log-likelihood ratio test?</li>
 	<li>Optional: Both theories mentioned earlier predict that the relationship between basal metabolic rate and body mass will conform to a power law --- in other words that the relationship between log(<i>BMR</i>) and log(<i>M</i>) will be linear. Is the relationship linear in mammals? Use AIC to compare the fit of a linear model fitted to the relationship between log(<i>BMR</i>) and log(<i>M</i>) with the fit of a quadratic regression of log(<i>BMR</i>) on log(<i>M</i>) (a model in which both log(<i>M</i>) and (log(<i>M</i>))<sup>2</sup> are included as terms). Don't force a slope of 2/3 or 3/4. Plot both the linear and quadratic regression curves with the data. Which model has the most support? Which has the least? On the basis of this analysis, does the relationship between basal metabolic rate and body mass in mammals conform to a power law?</li>
</ol>
<small>* 23.73591
** 9.99e-01 7.01e-06
</small>
<h2><a name="fragments"></a>Bird abundance in forest fragments</h2>
In the current example we are going data dredging, unlike the previous example. There are no candidate models. Let's just try all possibilities and see what turns up. The data include a set of possible explanatory variables and we want to known which model, of all possible models, is the best. Sensibly, we wish to identify both the best model and those models that are near-best and should be kept under consideration (e.g., for use in planning, or subsequent multimodel inference).

The response variable is the abundance of forest birds in 56 forest fragment in southeastern Australia by Loyn (1987, cited in Quinn and Keough [2002] and analyzed in their Box 6.2). Abundance is measured as the number of birds encountered in a timed survey (units aren't explained). Six predictor variables were measured in each fragment:
<ul>
 	<li><u>area</u>: fragment area (ha)</li>
 	<li><u>dist</u>: distance to the nearest other fragment (km)</li>
 	<li><u>ldist</u>: distance to the nearest larger fragment (km)</li>
 	<li><u>graze</u>: grazing pressure (1 to 5, indicating light to heavy)</li>
 	<li><u>alt</u>: altitude (m)</li>
 	<li><u>yr.isol</u>: number of years since fragmentation.</li>
</ul>
The data can be downloaded <a href="../../../data/birdabund.csv">HERE</a>.
<ol>
 	<li>Using histograms, scatter plots, or the <code>pairs</code> command, explore the frequency distributions of the variables. Several of the variables are highly skewed, which will lead to outliers having excessive leverage. Transform the highly skewed variables to solve this problem. (I log-transformed <code>area</code>, <code>dist</code> and <code>ldist</code>. The results are not perfect.)</li>
 	<li>Use the <code>cor</code> command to estimate the correlation between pairs of explanatory variables. The results will be easier to read if you round to just a couple of decimals. Which are the most highly correlated variables?</li>
 	<li>Using the model selection tool <code>dredge()</code> in the <code>MuMIn</code> package, determine which linear model best predicts bird abundance (use AIC as the criterion). Ignore interactions. (You will need to install the <code>MuMIn</code> package if you haven't yet done so.)</li>
 	<li>How many variables are included in the best model*?</li>
 	<li>How many models in total have an AIC difference less than or equal to 7?</li>
 	<li>Calculate the Akaike weights of all the models retained. How much weight is given to the best model**? Are there common features shared among the models having the highest weights?</li>
 	<li>How many models are in the "confidence set" whose cumulative weights reach 0.95***?</li>
 	<li>Use a linear model to fit the "best" model to the data. Produce a summary of the results. Use <code>visreg</code> to visualize the relationship between bird abundance and each of the three variables in the "best" model one at a time. Which variable has the strongest relationship with bird abundance in this model?</li>
</ol>
<small> * 3
** 0.127
*** 20
</small>

Optional: Let's try analyzing the data using <code>stepAIC</code>, which would also allow us to include interaction terms if we wished (not today).
<ol>
 	<li>Return to the data frame in which any variables requiring transformation have been replaced with the transformed variables.</li>
 	<li>Use <code>stepAIC</code> to find the "best" model (having no interaction terms). Review the results printed out on the screen. See the R tips pages on model selection (under Fit model) for help interpreting the steps.</li>
 	<li>Fit a linear model to the "best" model according to <code>stepAIC</code>. Is the best model the same or different from the one picked out by <code>leaps</code>?</li>
 	<li>Inspect the results of the linear model fit. If you use an ANOVA table, use Type III sums of squares, since the order of the variables in your formula could be viewed as arbitrary. Could stepwise regression used with null hypothesis significance testing have resulted in this model? How can you tell? Is it justifiable to keep terms in the "best" model that are not statistically significant according to basic significance testing?</li>
 	<li>Calculate AIC for the best model. Write this number down somewhere because we will compare it with another model fitted below. (Note: the AIC value that you compute will differ from that printed out by <code>stepAIC</code> for this model. Not to worry: <code>stepAIC</code> uses the command <code>extractAIC</code> instead of <code>AIC</code>. The computations yield results that differ only by a constant, so AIC differences are unaffected as long as the same method is applied to models being compared).</li>
 	<li>Run <code>stepAIC</code> again, but this time use a model that includes all two-way interaction terms. This is already pushing the data to the limit, because there are only 56 data points. Scan the printed output on the screen to see the sequence of steps that <code>stepAIC</code> takes to find the best model.</li>
 	<li>Summarize the results of fitting a linear model to the best-fitting model from (5). Is the best model the same or different from the one picked out in (1) from the analysis of the additive model?</li>
 	<li>Calculate AIC for the best model analyzed in (6). How does it compare to the AIC value computed in (4) for the best additive model (the best model without interaction terms)****? Considering the difference in AIC between the two models, which has more support? Do the two models have roughly equivalent support or does one have "essentially no support", as defined in lecture?</li>
</ol>