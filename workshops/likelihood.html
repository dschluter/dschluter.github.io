<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="" />


<title>Likelihood</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/yeti.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>




<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="workshops.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 45px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 50px;
  margin-top: -50px;
}
.section h2 {
  padding-top: 50px;
  margin-top: -50px;
}
.section h3 {
  padding-top: 50px;
  margin-top: -50px;
}
.section h4 {
  padding-top: 50px;
  margin-top: -50px;
}
.section h5 {
  padding-top: 50px;
  margin-top: -50px;
}
.section h6 {
  padding-top: 50px;
  margin-top: -50px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->



<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = false;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}

.tocify-subheader {
  display: inline;
}
.tocify-subheader .tocify-item {
  font-size: 0.95em;
}

</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">UBC Biology 501 R workshops</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../index.html">Biol 501 home</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    R Workshops
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="index.html">Main workshops page</a>
    </li>
    <li>
      <a href="workshops-intro.html">1. Introduction to R</a>
    </li>
    <li>
      <a href="graphics.html">2. Graphs and tables</a>
    </li>
    <li>
      <a href="exp-design.html">3. Plan experiments</a>
    </li>
    <li>
      <a href="linearmodels.html">4. Linear models</a>
    </li>
    <li>
      <a href="lme.html">5. Mixed-effects models</a>
    </li>
    <li>
      <a href="likelihood.html">6. Likelihood</a>
    </li>
    <li>
      <a href="glm.html">7. Generalized linear models</a>
    </li>
    <li>
      <a href="modelselection.html">8. Model selection</a>
    </li>
    <li>
      <a href="bayes.html">9. Bayesian inference</a>
    </li>
    <li>
      <a href="resampling.html">10. Bootstrap and permutation</a>
    </li>
    <li>
      <a href="meta.html">11. Meta-analysis</a>
    </li>
    <li>
      <a href="multivariate.html">12. Multivariate methods</a>
    </li>
    <li>
      <a href="phylogenetic.html">13. Phylogenetic comparative methods</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    R tips pages
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="https://www.zoology.ubc.ca/~schluter/R/index.html">R tips home page</a>
    </li>
    <li>
      <a href="https://www.zoology.ubc.ca/~schluter/R/Calculate.html">Calculate with R</a>
    </li>
    <li>
      <a href="https://www.zoology.ubc.ca/~schluter/R/Data.html">Data sets</a>
    </li>
    <li>
      <a href="https://www.zoology.ubc.ca/~schluter/R/Display.html">Graphs &amp; Tables</a>
    </li>
    <li>
      <a href="https://www.zoology.ubc.ca/~schluter/R/Plan.html">Planning tools</a>
    </li>
    <li>
      <a href="https://www.zoology.ubc.ca/~schluter/R/Loop.html">Loop, repeat</a>
    </li>
    <li>
      <a href="https://www.zoology.ubc.ca/~schluter/R/Model.html">Fit model</a>
    </li>
    <li>
      <a href="https://www.zoology.ubc.ca/~schluter/R/Prob.html">Probability &amp; Likelihood</a>
    </li>
    <li>
      <a href="https://www.zoology.ubc.ca/~schluter/R/Resample.html">Resample, Bootstrap</a>
    </li>
    <li>
      <a href="https://www.zoology.ubc.ca/~schluter/R/Meta.html">Meta-analysis</a>
    </li>
    <li>
      <a href="https://www.zoology.ubc.ca/~schluter/R/Multivariate.html">Multivariate methods</a>
    </li>
    <li>
      <a href="https://www.zoology.ubc.ca/~schluter/R/Phylogenetic.html">Phylogenetic comparison</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Likelihood</h1>

</div>


<p>In this workshop we will use likelihood methods to estimate parameters and test hypotheses. Likelihood methods are especially useful when modeling data having a probability distribution other than the normal distribution (e.g., binomial, exponential, etc). Refer to the “Probability” tab of the R tips web pages for instruction.</p>
<p><br></p>
<div id="maximum-likelihood-estimate" class="section level3">
<h3>Maximum likelihood estimate</h3>
<p>To estimate a parameter, we treat the data as given and vary the parameter to find that value for which the probability of obtaining the data is highest. This value is the <i>maximum likelihood estimate</i> of the parameter. The likelihood function is also used to obtain a likelihood-based confidence interval for the parameter. This confidence interval is a large-sample approximation, and may be inaccurate for small sample size, depending on the probability distribution of the data.</p>
<p><br></p>
</div>
<div id="log-likelihood-ratio-test" class="section level3">
<h3>Log-likelihood ratio test</h3>
<p>The log-likelihood ratio test can be used to compare the fits of two nested models to the same data. The “full” model fits the data using the maximum likelihood estimates for the parameter(s) of interest (for example, a proportion <i>p</i>). The “reduced” model constrains the parameter values to represent a null hypothesis (for example, that <i>p</i> = 0.5, or that <i>p</i> is equal between two treatments). The <i>G</i> statistic is calculated as twice the difference between the log-likelihoods of the two models (“full” minus “reduced”):</p>
<pre class="r"><code>G &lt;- 2 *(loglikefull - loglikereduced)</code></pre>
<p><i>G</i> is also known as the <i>deviance</i>. Under the null hypothesis, <i>G</i> has an approximate χ<sup>2</sup> distribution with degrees of freedom equal to the difference between the “full” and “reduced” models in the number of parameters estimated from data. We’ll work through an example below.</p>
<hr />
</div>
<div id="warmup" class="section level2">
<h2>Warmup</h2>
<p>We’ll start by getting familiar with the commands in R to calculate probabilities.</p>
<ol style="list-style-type: decimal">
<li>The probability of heads in a coin toss is 0.5. If you flip a coin 10 times, what is the probability of obtaining exactly 5 heads and 5 tails?</li>
<li>The fraction of human babies born who are boys is about 0.512. If 20 newborn babies are randomly sampled, what is the probability that exactly 10 are boys?</li>
<li>Plot the entire probability distribution for the number of boys in families having six children. Assume the probability that any one child is a boy is 0.512.</li>
<li>If mortality is independent of age, then the probability of surviving <i>X</i> years after birth, and then dying in the <i>X</i> + 1<sup>st</sup> year, will follow a geometric distribution. <i>X</i> is any integer from 0 to infinity. If the probability of dying in any given year is 0.1, what fraction of individuals are expected to survive 10 years and then die in their 11th year?*</li>
<li>Refer to the previous question. If the probability of death in any give year is 0.1, what fraction of individuals die before they reach their 6th birthday?**</li>
<li>In an environment where prey are randomly distributed, the search time between discovered prey items will follow an exponential distribution. Imagine an environment in which the mean search time between prey items is 0.5 hours. What is the probability density corresponding to a search time of 2 hours?***</li>
<li>Refer to the previous problem. Create a line plot of the exponential probability curve over most the range of possible values for search time between items (e.g., over the range of values between 0 and 5 hours).</li>
</ol>
<p><small>*0.03487</p>
<p>**0.46856</p>
<p>***0.03663 </small></p>
<!--

<br>

### Answers


```r
# 1.
dbinom(5, size=10, p=0.5)
```

```
## [1] 0.2460938
```

```r
# 2.
dbinom(10, size=20, p=0.512)
```

```
## [1] 0.1751848
```

```r
# 3.
z <- dbinom(0:6, size=6, p=0.512)
names(z) <- as.character(0:6)
barplot(z, space=0, ylab="Probability", col = "firebrick", las = 1, xlab = "Number of boys")
```

<img src="likelihood_files/figure-html/unnamed-chunk-2-1.png" width="528" />

```r
# 4.
dgeom(10, 0.1)
```

```
## [1] 0.03486784
```

```r
# 5.
sum(dgeom(0:5, 0.1))
```

```
## [1] 0.468559
```

```r
# 6.
dexp(2, rate=1/0.5)
```

```
## [1] 0.03663128
```

```r
# 7.
x <- seq(0, 5, by = 0.1)
y <- dexp(x, rate = 1/0.5)
plot(y ~ x, type = "l")
```

<img src="likelihood_files/figure-html/unnamed-chunk-2-2.png" width="528" />

[//]: -->
<hr />
</div>
<div id="left-handed-flowers" class="section level2">
<h2>Left-handed flowers</h2>
<p>Individuals of most plant species are hermaphrodites (with both male and female sexual organs) and are therefore prone to inbreeding of the worst sort: having sex with themselves. The mud plantain, <i>Heteranthera multiflora</i>, has a simple mechanism to avoid such “selfing.” The style deflects to the left in some individuals and to the right in others. The anther is on the opposite side. Bees visiting a left-handed plant are dusted with pollen on their right side, which then is deposited on the styles of only right-handed plants visited later. To investigate the genetics of this variation, Jesson and Barrett (2002, Proc. Roy. Soc. Lond., Ser. B, Biol. Sci. 269: 1835-1839) crossed pure strains of left- and right-handed flowers, yielding only right-handed F1 offspring, which were then crossed with one another. Six of the resulting F2 offspring were left-handed, and 21 were right-handed. The expectation under a simple model of inheritance would be that their F2 offspring should consist of left- and right-handed individuals in a 1:3 ratio (i.e., 1/4 of the plants should be left-handed). <!-- The data from this cross can be downloaded <a href="https://www.zoology.ubc.ca/~bio501/R/data/plantain.csv">here</a>. --></p>
<ol style="list-style-type: decimal">
<li>Generate a vector that includes a range of possible values for the population proportion of left-handed flowers, <i>p</i>, from 0.01 to 0.99 in increments of 0.01.</li>
<li>Given the results above, calculate the log-likelihood of each value for <i>p</i> in the F2 generation.</li>
<li>Create a line plot of the log-likelihood against the range of values for <i>p</i>. What is the resulting curve called? Can you see approximately the value of <i>p</i> corresponding to the highest point of the curve? What is this value called?</li>
<li>To get closer to this value, repeat steps (1) to (3) using a narrower range of values for <i>p</i> surrounding the highest point in the curve and an additional decimal point.</li>
<li>Use your results to determine the maximum likelihood estimate of the proportion of left-handed F2 flowers.</li>
<li>Provide a likelihood-based 95% confidence interval for the population proportion.*</li>
<li>(Optional) Use the <code>bbmle</code> package to find the maximum likelihood estimate and 95% confidence interval for the proportion of left-handed flowers. How do the results compare with your calculations?</li>
<li>We can compare the fits of two models to these same data, to test the null hypothesis that the proportion of left-handed flowers in the cross is 1/4 (i.e., the proportion predicted by the simplest genetic model for flower handedness). To begin, obtain the log-likelihood corresponding to the maximum likelihood estimate of the proportion of left-handed flowers. This represents the fit of the “full” model to the data. This model estimated one parameter from the data (<i>p</i>, estimated using maximum likelihood).</li>
<li>Now obtain the log-likelihood of the value for <i>p</i> specified by the null hypothesis. This represents the fit of the “reduced” model to the data. This reduced model estimated zero parameters from the data (instead, <i>p</i> was specified by the null hypothesis).</li>
<li>Calculate the <i>G</i> statistic for the log-likelihood ratio test**. To obtain a <i>P</i>-value for the test, calculate the tail probability from the <span class="math inline">\(\chi^2\)</span> distribution as follows,</li>
</ol>
<pre class="r"><code>1 - pchisq(G, df)</code></pre>
<p>where <code>df</code> is the degrees of freedom, calculated as the difference between the two models in the number of parameters estimated from the data.</p>
<ol start="11" style="list-style-type: decimal">
<li>Optional: How similar is the result from your log-likelihood ratio test to that from an ordinary <span class="math inline">\(\chi^2\)</span> goodness of fit test? Analyze the same data using the <code>chisq.test()</code> command in R and comment on the outcome.</li>
</ol>
<p><small>* 0.094 &lt; <i>p</i> &lt; 0.400 <br> ** 0.114</small></p>
<!--

<br>

### Answers


```r
# 1. Vector
p <- seq(0.01, 0.99, by = 0.01)

# 2. The log-likelihoods
loglike <- dbinom(6, size = 27, prob = p, log = TRUE)

# 3. Log-likelihood curve, showing maximum likelihood estimate
plot(loglike ~ p, xlab="Population proportion, p", ylab="Log-likelihood", type="l")
```

<img src="likelihood_files/figure-html/unnamed-chunk-4-1.png" width="528" />

```r
# 4. Narrower
p <- seq(0.05, 0.5, by = 0.001)
loglike <- dbinom(6, size = 27, prob = p, log = TRUE)
plot(loglike ~ p, xlab="Population proportion, p", ylab="Log-likelihood", type="l")

# 5. Maximum likelihood estimate
phat <- p[loglike == max(loglike)]
phat
```

```
## [1] 0.222
```

```r
# 6.
# 1.92-unit support limits. 
# This first method gives an interval slightly narrower than the real values
range(p[loglike >= (max(loglike) - 1.92)])
```

```
## [1] 0.095 0.399
```

```r
# To be conservative, take outer edge of this interval
max(p[loglike < (max(loglike) - 1.92) & p < 0.222])
```

```
## [1] 0.094
```

```r
min(p[loglike < (max(loglike) - 1.92) & p > 0.222])
```

```
## [1] 0.4
```

```r
# 7.
suppressPackageStartupMessages(library(bbmle))
```

<img src="likelihood_files/figure-html/unnamed-chunk-4-2.png" width="528" />

```r
pNegLogLike <- function(p){-dbinom(6, size=27, p, log=TRUE)}
z <- mle2(pNegLogLike, start=list(p=0.5))
```

```
## Warning in dbinom(6, size = 27, p, log = TRUE): NaNs produced

## Warning in dbinom(6, size = 27, p, log = TRUE): NaNs produced

## Warning in dbinom(6, size = 27, p, log = TRUE): NaNs produced

## Warning in dbinom(6, size = 27, p, log = TRUE): NaNs produced
```

```r
summary(z)
```

```
## Maximum likelihood estimation
## 
## Call:
## mle2(minuslogl = pNegLogLike, start = list(p = 0.5))
## 
## Coefficients:
##   Estimate Std. Error z value    Pr(z)   
## p 0.222223   0.080009  2.7775 0.005479 **
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## -2 log L: 3.407838
```

```r
pProfile <- profile(z)
confint(pProfile, method="uniroot")
```

```
##      2.5 %     97.5 % 
## 0.09494227 0.39989553
```

```r
# 8. Log likelihood full model
LLfull <- max(loglike)
LLfull
```

```
## [1] -1.703923
```

```r
# 9. Log likelihood reduced model

LLreduced <- loglike[p == 0.25]
LLreduced
```

```
## [1] -1.760941
```

```r
# 10. Log likelihood ratio statistic
G <- 2 * (LLfull - LLreduced)
G
```

```
## [1] 0.1140369
```

```r
1 - pchisq(G, 1)
```

```
## [1] 0.7355942
```

```r
# 11. Using chisq.test
chisq.test(c(6, 21), p = c(0.25, 0.75))
```

```
## 
##  Chi-squared test for given probabilities
## 
## data:  c(6, 21)
## X-squared = 0.11111, df = 1, p-value = 0.7389
```

[//]: -->
<hr />
</div>
<div id="counting-elephants" class="section level2">
<h2>Counting elephants</h2>
<p>Counting elephants is more challenging than you might think, at least when they live in dense forest and feed at night. Eggert et al. (2003. Molecular Ecology 12: 1389-1402) used mark-recapture methods to estimate the total number of forest elephants inhabiting Kakum National Park in Ghana without having to see a single one. They spent about two weeks in the park collecting elephant dung, from which they extracted elephant DNA. Using five genetic markers, they generated a unique DNA fingerprint for every elephant encountered in this way. Over the first seven days of collecting they identified 27 elephant individuals. Refer to these 27 elephants as <u>marked</u>. Over the next eight days they sampled 74 individuals, of which 15 had been previously marked. Refer to these 15 elephants as <u>recaptured</u>. We would like to use these numbers to estimate the total number of elephants in the park.</p>
<p>If we can make the following assumptions,</p>
<ul>
<li>
There were no births, deaths, immigrants, or emigrants while the study was being carried out, and
</li>
<li>
The dung of every elephant, marked or unmarked, regardless of its output, had an equal chance of being sampled, and selection of each individual was independent of the others.
</li>
</ul>
<p>then the number of recaptured (i.e., previously marked) individuals <i>X</i> in the second sample should have a hypergeometric distribution with parameters <i>k</i> (the size of the second sample of individuals), <i>m</i> (total number of marked individuals in the population), and <i>n</i> (total number of unmarked individuals in the population).</p>
<ol style="list-style-type: decimal">
<li>Using the appropriate command in R for the hypergeometric distribution, calculate the maximum likelihood estimate for the total number of elephants in the park. Note that the total number is <i>n</i> + <i>m</i>, where <i>n</i> is the unknown parameter to be estimated. Note also that only integer values for <i>n</i> are allowed, and that <i>n</i> cannot be smaller than <i>k</i> - <i>X</i>, the observed number of unmarked individuals in the second sample.*</li>
<li>Calculate a likelihood-based 95% confidence interval for the total number of elephants.**
</ol>
<small>* 133 ** 104 &lt; <i>N</i> &lt; 193 </small></li>
</ol>
<!--

<br>

### Answers


```r
# 1. Estimate N
m <- 27   # total marked individuals in the population
k <- 74   # size of second sample
X <- 15   # number of recaptures

# Note that N must be at least 86 = 74 - 15 + 27

N <- 86:200
loglike<-dhyper(15, 27, N - 27, 74, log = TRUE)
# or
loglike<-dhyper(X, m, n = N - 27, k, log = TRUE)

plot(loglike ~ N, type="l")
```

<img src="likelihood_files/figure-html/unnamed-chunk-5-1.png" width="528" />

```r
max(loglike)
```

```
## [1] -1.763941
```

```r
N[loglike == max(loglike)]
```

```
## [1] 133
```

```r
# 2. 95% confidence interval
z <- N[loglike < max(loglike) - 1.92]
c( max(z[z < 133]), min(z[z > 133]) )
```

```
## [1] 104 193
```

[//]: -->
<hr />
</div>
<div id="voyaging-voles" class="section level2">
<h2>Voyaging voles</h2>
<p>The movement or dispersal distance of organisms is often modeled using the geometric distribution, assuming steps are discrete rather than continuous. For example, M. Sandell, J. Agrell, S. Erlinge, and J. Nelson (1991. Oecologia 86: 153-158) measured the distance separating the locations where individual voles, <i>Microtus agrestis</i>, were first trapped and the locations they were caught in a subsequent trapping period, in units of the number of home ranges. The data for 145 male and female voles are <a href="https://www.zoology.ubc.ca/~bio501/R/data/vole.csv">here</a>. The variable “dispersal” indicates the distance moved (number of home ranges) from the location of first capture. If the geometric model is adequate, then Pr[<i>X</i> = 0 home ranges moved] = <i>p</i> Pr[<i>X</i> = 1 home ranges moved] = (1-<i>p</i>)<i>p</i> Pr[<i>X</i> = 2 home ranges moved] = (1-<i>p</i>)<sup>2</sup><i>p</i> and so on. <i>p</i> is the probability of success (capture) at each distance from the location of the first capture.</p>
<ol style="list-style-type: decimal">
<li>Tabulate the number of home ranges moved by voles in this study. Use the data from both sexes combined.</li>
<li>Using the appropriate commands in R, calculate the log-likelihood of each of a range of possible values for <i>p</i>, the parameter of the geometric distribution. Plot the log likelihood against <i>p</i>.</li>
<li>Calculate the maximum-likelihood estimate of <i>p</i> and the likelihood based 95% confidence interval.</li>
<li>Use the appropriate R command and the maximum likelihood estimate of <i>p</i> to calculate the predicted fraction of voles dispersing 0, 1, 2, 3, 4, and 5 home ranges.</li>
<li>Use the result in (3) to calculate the expected number* of voles (out of 145) dispersing 0 - 5 home ranges, assuming a geometric distribution. How does this compare with the observed frequencies?</li>
</ol>
<p><small>* 124.41 17.67 2.51 0.36 0.05 0.01</small></p>
<!--

<br>

### Answers


```r
x <- read.csv(url("https://www.zoology.ubc.ca/~bio501/R/data/vole.csv"), 
        stringsAsFactors = FALSE)
head(x)
```

```
##      sex dispersal
## 1 female         0
## 2 female         0
## 3 female         0
## 4 female         0
## 5 female         0
## 6   male         0
```

```r
# 1. Tabulate number of home ranges moved
table(x$dispersal)
```

```
## 
##   0   1   2 
## 123  20   2
```

```r
# 2. MLE of p
p <- seq(0.05, 0.95, by = 0.001)

# Using for loop
loglike <- vector()
for(i in 1:length(p)){
    loglike[i] <- sum(dgeom(x$dispersal, prob=p[i], log = TRUE) )
    }

plot(p, loglike, type="l", xlab="p", ylab="log likelihood")
```

<img src="likelihood_files/figure-html/unnamed-chunk-6-1.png" width="528" />

```r
# 3. MLE of p
max(loglike)
```

```
## [1] -69.0532
```

```r
phat <- p[loglike == max(loglike)]

z <- p[loglike < max(loglike) - 1.92]
c( max(z[z < 0.858]), min(z[z > 0.858]) )
```

```
## [1] 0.800 0.906
```

```r
# 4. Expected numbers 

frac <- dgeom(0:5, prob=phat)
round(frac,4)
```

```
## [1] 0.8580 0.1218 0.0173 0.0025 0.0003 0.0000
```

```r
expected <- frac * nrow(x)
round(expected, 2)
```

```
## [1] 124.41  17.67   2.51   0.36   0.05   0.01
```

```r
# Use the appropriate R command and the maximum likelihood estimate of p to calculate the 
# predicted fraction of voles dispersing 0, 1, 2, 3, 4, and 5 home ranges.

frac <- dgeom(0:5, prob=phat)
round(frac,4)
```

```
## [1] 0.8580 0.1218 0.0173 0.0025 0.0003 0.0000
```

```r
# Expected distances moved
dist <- nrow(x) * frac
round(dist, 2)
```

```
## [1] 124.41  17.67   2.51   0.36   0.05   0.01
```

```r
# Compare with observed:
table(x$dispersal)
```

```
## 
##   0   1   2 
## 123  20   2
```

[//]: -->
<hr />
</div>
<div id="life-of-bees" class="section level2">
<h2>Life of bees</h2>
<p>Life spans of individuals in a population are often approximated by an exponential distribution. To estimate the mortality rate of foraging honey bees, P. K. Visscher and R. Dukas (1997. Insectes Sociaux 44: 1-5) recorded the entire foraging life span of 33 individual worker bees in a local bee population in a natural setting. The 33 life spans (in hours) are <a href="https://www.zoology.ubc.ca/~bio501/R/data/bees.csv">here</a>.</p>
<ol style="list-style-type: decimal">
<li>Plot the frequency distribution of lifespans of the 33 bees. Choose the option to display probability density instead of raw frequency. Does the distribution of lifespans resemble an exponential distribution (make sure to try different bin widths of the histogram)?</li>
<li>Use the exponential approximation and maximum likelihood to estimate the hourly mortality rate of bees.*</li>
<li>Using the maximum likelihood estimate, calculate the probability density for the exponential distribution across a range of values for lifespan. Draw this relationship between probability and lifespan on top of the frequency distribution you plotted in (1). Comment on the fit between the data and the exponential distribution you fitted. Is the exponential distribution a good fit to these data?</li>
<li>Assume (for the purposes of this exercise) that an exponential probability model is reasonable. Calculate the likelihood-based 95% confidence interval for the mortality rate.**</li>
<li>Calculate the maximum likelihood estimate for the mean lifespan, with approximate 95% likelihood based confidence interval.***</li>
<li>(Optional) Use the <code>bbmle</code> package to find the maximum likelihood estimate and 95% confidence interval for the hourly mortality rate of bees. How do the results compare with your calculations?</li>
</ol>
<p><small> * 0.036 / hour</p>
<p>** (0.025, 0.050) / hour</p>
<p>*** 27.8 hours; 95% CI: (20, 40) hours</small></p>
<!--

<br>

### Answers


```r
bees <- read.csv(url("https://www.zoology.ubc.ca/~bio501/R/data/bees.csv"), 
          stringsAsFactors = FALSE)
head(bees)
```

```
##   id hours
## 1  1   7.1
## 2  2   2.3
## 3  3   9.6
## 4  4  25.8
## 5  5  14.6
## 6  6  12.8
```

```r
# 1. Plot histogram
hist(bees$hours, right = FALSE, col = "firebrick", prob = TRUE, 
      ylim = c(0,0.035), las = 1, breaks = 15)
```

<img src="likelihood_files/figure-html/unnamed-chunk-7-1.png" width="528" />

```r
# 2. MLE of rate (in per hour units)
rate <- seq(.001, .1, by=.001)

# Using for loop
loglike <- vector()
for(i in 1:length(rate)){
    loglike[i] <- sum(dexp(bees$hours, rate = rate[i], log = TRUE))
    }

plot(rate, loglike, type="l")
```

<img src="likelihood_files/figure-html/unnamed-chunk-7-2.png" width="528" />

```r
max(loglike)
```

```
## [1] -142.7838
```

```r
mlrate <- rate[loglike==max(loglike)] # per hour
mlrate
```

```
## [1] 0.036
```

```r
# 3. Exponential might not be a great fit
hist(bees$hours, right = FALSE, col = "firebrick", prob = TRUE, 
      ylim = c(0,0.035), las = 1, breaks = 15)

x <- bees$hours[order(bees$hours)]
y <- dexp(x, rate = 0.036)
lines(x, y, lwd=2)
```

<img src="likelihood_files/figure-html/unnamed-chunk-7-3.png" width="528" />

```r
# 4. 95% confidence interval
z <- rate[loglike < max(loglike) - 1.92]
c( max(z[z < mlrate]), min(z[z > mlrate]) )
```

```
## [1] 0.025 0.050
```

```r
# 5. Mean lifespan
1/mlrate
```

```
## [1] 27.77778
```

```r
1/c( max(z[z < mlrate]), min(z[z > mlrate]) )
```

```
## [1] 40 20
```

```r
# bbmle package
suppressPackageStartupMessages(library(bbmle))

pNegLogLike <- function(rate){-sum(dexp(bees$hours, rate=rate, log=TRUE))}
suppressWarnings(
  z <- mle2(pNegLogLike, start=list(rate = 1))
  )

summary(z)
```

```
## Maximum likelihood estimation
## 
## Call:
## mle2(minuslogl = pNegLogLike, start = list(rate = 1))
## 
## Coefficients:
##       Estimate Std. Error z value     Pr(z)    
## rate 0.0359102  0.0062512  5.7446 9.216e-09 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## -2 log L: 285.5674
```

```r
pProfile <- profile(z)

confint(pProfile, method="uniroot")
```

```
##      2.5 %     97.5 % 
## 0.02500926 0.04959301
```

[//]: -->
<!-- ##### Removed in 2019 #####
***

## Illegal tender
Jenkins (2001, Forensic Sci Int 121: 189-193) collected 50 US 1-dollar bills and tested them for drug contamination. Forty six of the bills were found to contain trace amounts of cocaine (subsequent studies have corroborated this astonishing finding -- can you think of a reason?). Let's use these data to estimate the proportion of contaminated bills in the US dollar population. For the purposes of this exercise, assume that the sample of bills was a random sample (in fact, 10 bills were sampled from each of 5 cities).

1. Generate a vector that includes a range of possible values for the population proportion <i>p</i>, from 0.01 to 0.99 in increments of 0.01.
2. Given the dollar bill data above, calculate the log-likelihood of each value for <i>p</i>.
3. Create a line plot of the log-likelihood against the range of values for <i>p</i>. What is the resulting curve called? Can you see approximately the value of <i>p</i> corresponding to the highest point of the curve? What is this value called?
4. To get closer to this value, repeat steps (1) to (3) using a narrower range of values for <i>p</i> surrounding the highest point in the curve.
5. Use your results to determine the maximum likelihood estimate of the proportion of US 1-dollar bills contaminated with cocaine.
6. Provide a likelihood-based 95% confidence interval for the population proportion.*

<small>*0.823 < <i>p</i> < 0.975 </small>

<br>

### Answers


```r
# 1. Vector
p <- seq(0.01, 0.99, by = 0.01)

# 2. The log-likelihoods
loglike <- dbinom(46, size = 50, prob = p, log = TRUE)

# 3. Log-likelihood curve, showing maximum likelihood estimate
plot(loglike ~ p, xlab="Population proportion, p", ylab="Log-likelihood", type="l")
```

<img src="likelihood_files/figure-html/unnamed-chunk-8-1.png" width="528" />

```r
# 4. Narrower
p <- seq(0.8, 0.99, by = 0.001)
loglike <- dbinom(46, size = 50, prob = p, log = TRUE)
plot(loglike ~ p, xlab="Population proportion, p", ylab="Log-likelihood", type="l")
```

<img src="likelihood_files/figure-html/unnamed-chunk-8-2.png" width="528" />

```r
# 5. Maximum likelihood estimate
phat <- p[loglike == max(loglike)]
phat
```

```
## [1] 0.92
```

```r
# 6.
# 1.92-unit support limits. This method gives an interval slightly narrower than the real values
range(p[loglike >= (max(loglike) - 1.92)])
```

```
## [1] 0.824 0.974
```

```r
# To be conservative, take outer edge of this interval
max(p[loglike < (max(loglike) - 1.92) & p < 0.92])
```

```
## [1] 0.823
```

```r
min(p[loglike < (max(loglike) - 1.92) & p > 0.92])
```

```
## [1] 0.975
```
-->
</div>

&nbsp;
<hr />
<p style="text-align: left;">
&copy; 2009-2020 Dolph Schluter
</p>
&nbsp;


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
